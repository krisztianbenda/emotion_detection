{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rocky-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition as fr\n",
    "import pandas as pd\n",
    "from os import listdir, path, getcwd, mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sudden-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = \"./images/train\"\n",
    "test_images_path = \"./images/test\"\n",
    "gathered_landmarks = ['chin', 'left_eyebrow', 'right_eyebrow', 'nose_bridge', 'nose_tip', 'left_eye', 'right_eye',\n",
    "                     'top_lip', 'bottom_lip']\n",
    "emotions = ['Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reflected-scottish",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'images/train/Anger/trainAnger001_031.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ffdbbde78009>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"images/train/Anger/trainAnger001_031.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mface_landmarks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_landmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/face_recognition/api.py\u001b[0m in \u001b[0;36mload_image_file\u001b[0;34m(file, mode)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mcontents\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2903\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2904\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2905\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images/train/Anger/trainAnger001_031.jpg'"
     ]
    }
   ],
   "source": [
    "image = fr.load_image_file(\"images/train/Anger/trainAnger001_031.jpg\")\n",
    "face_landmarks_list = fr.face_landmarks(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_landmarks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "paperback-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_df(data, columns, df):\n",
    "    if 'test' not in data[0]:\n",
    "        for emotion in emotions:\n",
    "            columns.append('is' + emotion)\n",
    "            if emotion in data[0]:\n",
    "                data.append(1)\n",
    "            else:\n",
    "                data.append(0)\n",
    "    df = df.append(pd.DataFrame([data], columns=columns), ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def get_landmarks(image):\n",
    "    marks = fr.face_landmarks(fr.load_image_file(image))\n",
    "    try:\n",
    "        marks[0]['chin'] = [marks[0]['chin'][8]] # only the middle point\n",
    "        marks[0]['left_eyebrow'] = [marks[0]['left_eyebrow'][0], marks[0]['left_eyebrow'][-1]] # first and last point\n",
    "        marks[0]['right_eyebrow'] = [marks[0]['right_eyebrow'][0], marks[0]['right_eyebrow'][-1]] # first and last point\n",
    "        marks[0]['nose_bridge'] = [marks[0]['nose_bridge'][0]] # first\n",
    "        marks[0]['nose_tip'] = [marks[0]['nose_tip'][2]] # middle\n",
    "        marks[0]['left_eye'] = [marks[0]['left_eye'][0]]\n",
    "        marks[0]['right_eye'] = [marks[0]['right_eye'][0]]\n",
    "        marks[0]['top_lip'] = [marks[0]['top_lip'][0], marks[0]['top_lip'][-1]]\n",
    "        marks[0]['bottom_lip'] = [marks[0]['bottom_lip'][0], marks[0]['bottom_lip'][-1]]\n",
    "        return marks\n",
    "    except:\n",
    "        print(\"WARN: There is no landmarks as expected: \", marks)\n",
    "        return []\n",
    "\n",
    "\n",
    "def data_extraction(images_path):\n",
    "    person = \"\"\n",
    "    data = []\n",
    "    columns = ['video']\n",
    "    df = pd.DataFrame()\n",
    "    for image in sorted(listdir(images_path)):\n",
    "        if not '.jpg' in image:\n",
    "            continue\n",
    "            \n",
    "        if person == image.split('_')[0]:\n",
    "            warned = False\n",
    "            new_frame = image.split('_')[1].split('.')[0]\n",
    "            new_landmarks = get_landmarks(path.join(images_path, image))\n",
    "            if len(landmarks) == 0:\n",
    "                landmarks = new_landmarks\n",
    "            for gathered_landmark in gathered_landmarks:\n",
    "                for idx, point in enumerate(landmarks[0][gathered_landmark]):\n",
    "                    try:\n",
    "                        if len(new_landmarks[0][gathered_landmark]) != len(landmarks[0][gathered_landmark]):\n",
    "                            print(\" WARN: can't find the proper number of points for image: \" + image)\n",
    "                            print(\" WARN: landmark: \" + gathered_landmark)\n",
    "                            print(\" WARN: number of points: \", len(new_landmarks[0][gathered_landmark]))\n",
    "                            print(\" WARN: number of expected points: \", len(landmarks[0][gathered_landmark]))\n",
    "                   \n",
    "                        distanceX = point[0] - new_landmarks[0][gathered_landmark][idx][0]\n",
    "                        distanceY = point[1] - new_landmarks[0][gathered_landmark][idx][1]\n",
    "                    \n",
    "                        columns.append(str(frame_count) + '-' + str(frame_count+1) + '_' + gathered_landmark + str(idx) + 'X')\n",
    "                        data.append(distanceX)\n",
    "\n",
    "                        columns.append(str(frame_count) + '-' + str(frame_count+1) + '_' + gathered_landmark + str(idx) + 'Y')\n",
    "                        data.append(distanceY)\n",
    "                    except:\n",
    "                        if not warned:\n",
    "                            print(\" WARN: can't find the proper landmarks for image: \" + image)\n",
    "                            print(\" WARN: found landmarks: \", new_landmarks)\n",
    "                            print(\" WARN: searching for: \" + gathered_landmark)\n",
    "                            warned = True\n",
    "                        columns.append(str(frame_count) + '-' + str(frame_count+1) + '_' + gathered_landmark + str(idx) + 'X')\n",
    "                        data.append(0)\n",
    "                        columns.append(str(frame_count) + '-' + str(frame_count+1) + '_' + gathered_landmark + str(idx) + 'Y')\n",
    "                        data.append(0)\n",
    "                        \n",
    "            landmarks = new_landmarks\n",
    "            frame = new_frame\n",
    "            frame_count+=1\n",
    "        else:\n",
    "            if len(data) != 0:\n",
    "                df = append_to_df(data, columns, df)\n",
    "            landmarks = get_landmarks(path.join(images_path, image))\n",
    "            person = image.split('_')[0]\n",
    "            frame = image.split('_')[1].split('.')[0]\n",
    "            frame_count = 0\n",
    "            print(person, frame)\n",
    "            data = [person]\n",
    "            columns = ['video']\n",
    "            \n",
    "    df = append_to_df(data, columns, df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "permanent-title",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "Processing emotion: Anger\n",
      "trainAnger001 012\n",
      "trainAnger002 012\n",
      "trainAnger003 012\n",
      "trainAnger004 013\n",
      "trainAnger005 018\n",
      "trainAnger006 008\n",
      "trainAnger007 008\n",
      "trainAnger008 008\n",
      "trainAnger009 008\n",
      "trainAnger010 009\n",
      "trainAnger011 013\n",
      "trainAnger012 013\n",
      "trainAnger013 012\n",
      "trainAnger014 011\n",
      "trainAnger015 011\n",
      "trainAnger016 010\n",
      "trainAnger017 009\n",
      "trainAnger018 009\n",
      "trainAnger019 007\n",
      "trainAnger020 008\n",
      "trainAnger021 008\n",
      "trainAnger022 007\n",
      "trainAnger023 007\n",
      "trainAnger024 007\n",
      "trainAnger025 008\n",
      "trainAnger026 008\n",
      "trainAnger027 008\n",
      "trainAnger028 009\n",
      "trainAnger029 011\n",
      "trainAnger030 014\n",
      "trainAnger031 014\n",
      "trainAnger032 012\n",
      "trainAnger033 012\n",
      "trainAnger034 009\n",
      "trainAnger035 009\n",
      "trainAnger036 012\n",
      "trainAnger037 011\n",
      "trainAnger038 012\n",
      "trainAnger039 011\n",
      "trainAnger040 011\n",
      "trainAnger041 012\n",
      "trainAnger042 013\n",
      "trainAnger043 009\n",
      "trainAnger044 010\n",
      "trainAnger045 009\n",
      "trainAnger046 010\n",
      "trainAnger047 009\n",
      "trainAnger048 010\n",
      "trainAnger049 010\n",
      "trainAnger050 010\n",
      "trainAnger051 010\n",
      "trainAnger052 010\n",
      "trainAnger053 011\n",
      "trainAnger054 013\n",
      "trainAnger055 013\n",
      "trainAnger056 013\n",
      "trainAnger057 013\n",
      "trainAnger058 013\n",
      "trainAnger059 012\n",
      "trainAnger060 013\n",
      "trainAnger061 010\n",
      "trainAnger062 011\n",
      "trainAnger063 009\n",
      "trainAnger064 012\n",
      "trainAnger065 011\n",
      "trainAnger066 009\n",
      "trainAnger067 008\n",
      "trainAnger068 010\n",
      "trainAnger069 011\n",
      "trainAnger070 010\n",
      "trainAnger071 012\n",
      "trainAnger072 011\n",
      "trainAnger073 011\n",
      "===================\n",
      "Processing emotion: Anger 2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-37a8c399e64c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing emotion: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0memotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-356497245147>\u001b[0m in \u001b[0;36mdata_extraction\u001b[0;34m(images_path)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'video'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappend_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-356497245147>\u001b[0m in \u001b[0;36mappend_to_df\u001b[0;34m(data, columns, df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mappend_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m'test'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0memotion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memotions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'is'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0memotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0memotion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    df = pd.DataFrame()\n",
    "    for emotion in sorted(listdir(train_images_path)):\n",
    "        if not path.isdir(path.join(train_images_path, emotion)):\n",
    "            continue\n",
    "        print(\"===================\")\n",
    "        print(\"Processing emotion: \" + emotion)\n",
    "\n",
    "        df = df.append(data_extraction(path.join(train_images_path, emotion)), ignore_index=True)\n",
    "        \n",
    "    df.to_csv('train.csv')\n",
    "    print(\"|=|+|+|+|+|+|+|+|++||++|+|+|\")\n",
    "    print(\"Processing test videos: \")\n",
    "    df = pd.DataFrame()\n",
    "    df = data_extraction(path.join(test_images_path))\n",
    "    df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "df. head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-thong",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
